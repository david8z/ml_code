createdAt: "2018-12-26T10:15:39.991Z"
updatedAt: "2019-04-23T16:25:23.708Z"
type: "MARKDOWN_NOTE"
folder: "b8e56f186b2ed2a7d2c5"
title: "Clustering"
content: '''
  # Clustering
  
  According to _Anderberg, 1973_, the aim of clustering is:
  >To group objects in classes so the objects belonging to the same class have a **high degree of natural association**, while the other classes are relatively different. The purpose is to create classes that are relatively different from each other.
  >
  ---
  Clustering is one of the big areas inside machine learning, is a type of unsupervised learning (using unlabel data). We can distinguish two types of clustering **partitional** and **hiierarchical**.
  
  ## Partitional Clustering
  The best solution will be the one that minimizes the distorion function J for every partition (K = ${1,2,3...}$). This means that we will try to minimize the SSE for each cluster.
  
  >We denote the points belonging to a cluster $c$ as $X_c$ and the centroid or mean of the cluster as $m_c$.
  >$\\rightarrow x \\in X_c:SE=||x-m_c||^2$
  >$\\rightarrow m_c=\\dfrac{1}{|X_c|}\\sum\\limits_{x\\in X_c}x$
  
  So we will try so minimize the SSE value of a apartition that is the sum of SSE of all the clusters of a given partition.
'''
tags: []
isStarred: false
isTrashed: false
isPinned: true
